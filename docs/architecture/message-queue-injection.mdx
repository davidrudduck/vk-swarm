---
title: "Message Queue Injection"
description: "Technical architecture for live message injection and auto-removal"
sidebarTitle: "Message Injection"
---

## Overview

The message queue injection system enables real-time communication with running AI coding agents. When a user adds a message, it is:

1. Added to the backend queue (for persistence and retry)
2. Immediately injected into the running process via stdin
3. Automatically removed from the queue if injection succeeds

This document describes the technical implementation.

## Data Flow

```text
User adds message
       │
       ▼
┌─────────────────────────┐
│  useMessageQueueInjection │  Hook: addAndInject()
│  (addMessage + inject)   │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  messageQueueApi.add()   │  POST /api/task-attempts/{id}/message-queue
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  executionProcessesApi   │  POST /api/execution-processes/{id}/inject-message
│  .injectMessage()        │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  container.rs            │  inject_message() -> get_protocol_peer()
│  inject_message()        │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  ProtocolPeer            │  send_user_message() writes to stdin
│  send_user_message()     │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  Claude Code Process     │  Receives message via stdin JSON-RPC
└──────────┬──────────────┘
           │
    { injected: true }
           │
           ▼
┌─────────────────────────┐
│  useMessageQueueInjection │  Calls removeMessage(message.id)
│  (auto-remove)           │
└─────────────────────────┘
```

## Key Components

### Frontend

| File | Purpose |
|------|---------|
| `frontend/src/hooks/message-queue/useMessageQueueInjection.ts` | Main hook combining queue + injection |
| `frontend/src/hooks/message-queue/useMessageQueue.ts` | Queue CRUD operations |
| `frontend/src/components/tasks/message-queue/MessageQueueBadge.tsx` | Toolbar badge UI |

### Backend

| File | Purpose |
|------|---------|
| `crates/server/src/routes/execution_processes.rs:214` | `inject_message()` route handler |
| `crates/local-deployment/src/container.rs:1542` | `inject_message()` implementation |
| `crates/executors/src/executors/claude/protocol.rs` | `ProtocolPeer` stdin management |

## User Message Card Design

All user messages (both initial and injected) now use a consistent green-styled card format with the following features:

### Visual Design

- **Border**: `border-green-400/40`
- **Header Background**: `bg-green-50 dark:bg-green-950/20`
- **Header Text**: `text-green-700 dark:text-green-300`
- **Content Background**: `bg-green-50 dark:bg-green-950/10`
- **Content Text**: Markdown-rendered with proper syntax highlighting

### Card Layout

```text
┌─────────────────────────────────────────┐
│ ClaudeCode / opus                    ▼  │  ← Header (executor/variant + chevron)
├─────────────────────────────────────────┤
│ Please fix the bug in auth.ts           │  ← Content (markdown rendered)
│ and run the tests afterwards.           │
└─────────────────────────────────────────┘
```

### Collapsible Long Messages

Messages longer than 5 lines are automatically collapsed by default:

- **Collapsed State**: Shows first 5 lines with "..." suffix
- **Expand/Collapse**: Chevron button in header (rotates on toggle)
- **State Persistence**: Uses `useExpandable` store keyed by `user-message:{executionProcessId}`

#### Implementation

```typescript
// frontend/src/components/NormalizedConversation/UserMessage.tsx
const LINE_LIMIT = 5;
const lineCount = content.split('\n').length;
const needsCollapse = lineCount > LINE_LIMIT;

const [expanded, toggle] = useExpandable(
  `user-message:${executionProcessId}`,
  !needsCollapse  // Default: expanded if short, collapsed if long
);

const displayContent = needsCollapse && !expanded
  ? content.split('\n').slice(0, LINE_LIMIT).join('\n') + '...'
  : content;
```

### Executor Context Display

The card header shows the executor and variant that was used:

```typescript
const executor = taskAttempt?.executor;
const variant = taskAttempt?.executor_variant;

// Header displays: "ClaudeCode / opus" or just "ClaudeCode" if no variant
<span>{executor}{variant && ` / ${variant}`}</span>
```

This helps users understand which agent configuration was active when the message was sent.

## API Endpoints

### POST `/api/task-attempts/{id}/message-queue`

Add a message to the queue.

**Request:**
```json
{
  "content": "Please also add input validation",
  "variant": null
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "content": "Please also add input validation",
    "variant": null,
    "position": 0
  }
}
```

### DELETE `/api/task-attempts/{id}/message-queue/{msgId}`

Remove a message from the queue.

**Response:**
```json
{
  "success": true,
  "data": null
}
```

### POST `/api/execution-processes/{id}/inject-message`

Inject a message into a running process.

**Request:**
```json
{
  "content": "Please also add input validation"
}
```

**Response (success):**
```json
{
  "success": true,
  "data": {
    "injected": true
  }
}
```

**Response (process not accepting input):**
```json
{
  "success": true,
  "data": {
    "injected": false
  }
}
```

**Response (process not running):**
```json
{
  "success": false,
  "message": "Cannot inject message: process is not running (status: Completed)"
}
```

## Injection Mechanics

### Protocol Peer

Each running Claude Code process has an associated `ProtocolPeer` that manages bidirectional communication:

```rust
// crates/local-deployment/src/container.rs
async fn inject_message(
    &self,
    execution_process_id: Uuid,
    message: String,
) -> Result<bool, ContainerError> {
    if let Some(peer) = self.get_protocol_peer(&execution_process_id).await {
        peer.send_user_message(message).await?;
        Ok(true)
    } else {
        Ok(false)
    }
}
```

The peer lookup uses a concurrent `DashMap` keyed by `execution_process_id`.

### EntryIndexProvider Sharing

**Problem:** When a message is injected, new output from the executor appeared **above** the injected message instead of **below** it in chronological order.

**Root Cause:** The `EntryIndexProvider` created during `normalize_logs()` was never stored/shared with `inject_message()`. When injection occurred, a NEW provider was created by scanning the message store, causing index collisions with the normalisation task's provider.

**Solution:** Share the same `EntryIndexProvider` instance between `normalize_logs()` and `inject_message()`:

1. **Container creates provider**: Before calling `normalize_logs()`, the container service creates an `EntryIndexProvider` and stores it
2. **Pass to normalize_logs**: The provider is passed as a parameter to the executor's `normalize_logs()` method
3. **Reuse in inject_message**: When injecting a message, `inject_message()` retrieves the stored provider instead of creating a new one

#### Implementation

```rust
// crates/services/src/services/container.rs
if let Some(executor) = ExecutorConfigs::get_cached().get_coding_agent(executor_profile_id) {
    // Create and store the provider FIRST
    let entry_index_provider = executors::logs::utils::EntryIndexProvider::start_from(&msg_store);
    self.store_entry_index_provider(execution_process.id, entry_index_provider.clone()).await;

    // Pass the same provider to normalize_logs
    let handle = executor.normalize_logs(msg_store, &worktree_path, entry_index_provider);
    self.store_normalization_handle(execution_process.id, handle).await;
}
```

```rust
// crates/local-deployment/src/container.rs (inject_message)
let index_provider = self.get_entry_index_provider(&execution_process_id).await
    .unwrap_or_else(|| {
        tracing::warn!(
            execution_process_id = %execution_process_id,
            "Entry index provider not found, creating fallback"
        );
        EntryIndexProvider::start_from(msg_store)
    });
```

This ensures that all log entries (both from normal execution and injected messages) use consistent, non-colliding indices, maintaining correct chronological order in the conversation view.

### Message Format

Messages are sent to Claude Code via JSON-RPC format on stdin:

```json
{
  "jsonrpc": "2.0",
  "method": "send_user_message",
  "params": {
    "content": "Please also add input validation"
  }
}
```

## Auto-Remove Logic

The `useMessageQueueInjection` hook handles automatic removal:

```typescript
const addAndInject = async (content, variant) => {
  // 1. Add to queue first (persistence)
  // Note: variant is always null - injected messages use executor's current mode
  const message = await addMessage(content, null);

  if (runningProcessId) {
    try {
      // 2. Inject into running process
      const result = await executionProcessesApi.injectMessage(
        runningProcessId,
        content
      );

      if (result.injected) {
        // 3. Remove from queue on success
        await removeMessage(message.id);
        return { queued: false, injected: true };
      }
    } catch (error) {
      // Keep in queue on error
      return { queued: true, injected: false };
    }
  }

  return { queued: true, injected: false };
};
```

### Return Values

| Scenario | `queued` | `injected` |
|----------|----------|------------|
| No running process | `true` | `false` |
| Injection succeeded | `false` | `true` |
| Injection failed | `true` | `false` |
| Network error | `true` | `false` |

## No Auto-Consume on Completion

**Important**: The message queue is NOT automatically consumed when an executor finishes. This design decision gives users full control:

- Messages stay in the queue until manually injected or removed
- No unexpected automatic executions when a process completes
- Users can review output before sending follow-ups

The `try_consume_queued_message()` call in `container.rs` is intentionally disabled to achieve this behavior.

## Error Handling

### Frontend

- Injection errors are logged but not thrown
- Message remains in queue for retry
- `lastInjectionError` state available for UI feedback

### Backend

- Process status checked before injection attempt
- Returns 400 Bad Request if process not running
- Returns `{ injected: false }` if no protocol peer found

## Toolbar Badge UI

The `MessageQueueBadge` component displays in the toolbar:

```tsx
<Popover>
  <PopoverTrigger>
    <Button>
      <MessageSquareDashed />
      <span className="hidden sm:inline">Messages</span>
      <span>({queue.length})</span>
    </Button>
  </PopoverTrigger>
  <PopoverContent>
    {/* Queue items with edit/remove/reorder controls */}
  </PopoverContent>
</Popover>
```

### Responsive Behavior

| Breakpoint | Display |
|------------|---------|
| `< sm` (640px) | Icon + count only |
| `>= sm` | Icon + "Messages" label + count |

### Touch Targets

All interactive elements meet 44px minimum touch target for mobile accessibility.

## Related Documentation

- [Executor Architecture](/architecture/executors) - How AI agent processes are managed
- [Message Queue User Guide](/core-features/message-queue) - End-user documentation
