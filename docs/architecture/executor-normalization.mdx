---
title: "Executor Log Normalization"
description: "How Vibe Kanban normalizes AI coding agent logs into a unified format for display and analysis"
sidebarTitle: "Log Normalization"
---

## Overview

AI coding agents output logs in vastly different formats - some use JSONL, others plain text, and some use custom streaming protocols. Vibe Kanban's log normalization system transforms these diverse outputs into a unified `NormalizedEntry` format that can be displayed consistently in the UI.

## Architecture

```text
┌─────────────────┐     ┌──────────────────┐     ┌────────────────┐
│  Agent Output   │────▶│  Log Normalizer  │────▶│ NormalizedEntry│
│  (varies)       │     │  (per-executor)  │     │ (unified)      │
└─────────────────┘     └──────────────────┘     └────────────────┘
         │                       │
         │              ┌────────┴────────┐
         │              │                 │
         ▼              ▼                 ▼
    • JSONL         • Claude parser   • Tool calls
    • Plain text    • Codex parser    • Messages
    • Stderr        • ACP parser      • Errors
```

### Key Components

| Component | Location | Purpose |
|-----------|----------|---------|
| `NormalizedEntry` | `crates/executors/src/logs/mod.rs` | Core normalized log structure |
| `NormalizedEntryType` | `crates/executors/src/logs/mod.rs` | Entry type discriminator |
| `ToolStatus` | `crates/executors/src/logs/mod.rs` | Tool execution status tracking |
| `NormalizedEntryError` | `crates/executors/src/logs/mod.rs` | Error classification system |
| Per-executor normalizers | `crates/executors/src/executors/*/` | Format-specific parsers |

## Normalized Entry Structure

Every log entry is normalized to this structure:

```rust
pub struct NormalizedEntry {
    pub timestamp: Option<String>,
    pub entry_type: NormalizedEntryType,
    pub content: String,
    pub metadata: Option<serde_json::Value>,
}
```

### Entry Types

The `NormalizedEntryType` enum captures all possible log entry kinds:

| Type | Description |
|------|-------------|
| `UserMessage` | User input sent to the agent |
| `UserFeedback` | User response to tool approval (deny with feedback) |
| `AssistantMessage` | Agent's text responses |
| `ToolUse` | Tool invocation with name, action type, and status |
| `SystemMessage` | System-level messages (model info, configuration) |
| `ErrorMessage` | Errors with classification |
| `Thinking` | Agent's reasoning/thought process |
| `Loading` | Loading/processing indicators |
| `NextAction` | Agent ready for next instruction |
| `ExecutionStart` | Execution process started (injected by frontend) |
| `ExecutionEnd` | Execution process completed (injected by frontend) |

## Tool Status Tracking

Tools go through various states during execution:

```rust
pub enum ToolStatus {
    Created,                    // Tool invoked, running
    Success,                    // Completed successfully
    Failed,                     // Execution failed
    Denied { reason, source },  // User/system denied execution
    PendingApproval { ... },    // Awaiting user approval
    TimedOut { waited_seconds }, // Approval timed out
    PendingQuestion { ... },    // Awaiting user answer
    Answered { answers },       // User answered question
}
```

### Denial Sources

When a tool is denied, the source is tracked:

| Source | Description |
|--------|-------------|
| `User` | User explicitly denied via UI |
| `Hook` | Pre-flight hook or check denied |
| `Policy` | Permission policy denied |
| `System` | System/executor denied |

### Timeout Context

When approvals time out, the wait duration is captured:

```rust
ToolStatus::TimedOut {
    waited_seconds: Some(30),  // How long we waited
}
```

## Error Classification

Errors are automatically classified using pattern matching on error messages:

```rust
pub enum NormalizedEntryError {
    SetupRequired,      // Authentication/login required
    RateLimited,        // Rate limits, quotas (429)
    NetworkError,       // Connection issues, timeouts
    ToolExecutionError, // Tool/command failures
    PermissionDenied,   // 403/401 errors
    ApiError,           // API/model errors (500s)
    Other,              // Unclassified errors
}
```

### Classification Patterns

The `NormalizedEntryError::classify()` method matches error messages:

| Error Type | Example Patterns |
|------------|------------------|
| `SetupRequired` | "authentication required", "login required", "not authenticated" |
| `RateLimited` | "rate limit", "429", "quota exceeded", "throttle" |
| `NetworkError` | "connection refused", "timeout", "ECONNREFUSED" |
| `PermissionDenied` | "permission denied", "forbidden", "403" |
| `ToolExecutionError` | "tool execution failed", "command failed" |
| `ApiError` | "api error", "500", "503", "service unavailable" |

## Action Types

Tool actions are categorized for rich UI rendering:

```rust
pub enum ActionType {
    FileRead { path },
    FileEdit { path, changes },
    CommandRun { command, result },
    Search { query },
    WebFetch { url },
    Tool { tool_name, arguments, result },
    TaskCreate { description },
    PlanPresentation { plan },
    TodoManagement { todos, operation },
    Other { description },
}
```

### File Changes

File edit operations include detailed change tracking:

```rust
pub enum FileChange {
    Write { content },           // Create/overwrite file
    Delete,                      // Delete file
    Rename { new_path },         // Rename file
    Edit { unified_diff, ... },  // Edit with diff
}
```

## Executor-Specific Implementations

### Claude Code

- **Format**: JSON-RPC over stdin/stdout
- **Parser**: `crates/executors/src/executors/claude/`
- **Features**: Tool calls, approvals, MCP integration, streaming

### Codex (OpenAI)

- **Format**: JSON-RPC with custom events
- **Parser**: `crates/executors/src/executors/codex/`
- **Features**: Tool calls, approvals, sessions, token usage

### ACP (Gemini, Qwen)

- **Format**: Agent Communication Protocol
- **Parser**: `crates/executors/src/executors/acp/`
- **Features**: Session management, plans, thoughts, tool calls

### Cursor

- **Format**: JSONL stdout
- **Parser**: `crates/executors/src/executors/cursor.rs`
- **Features**: Tool calls, MCP integration

### Copilot

- **Format**: Plain text stdout + log files
- **Parser**: `crates/executors/src/executors/copilot.rs`
- **Features**: Log file parsing for model info

### Opencode

- **Format**: Plain text + share bridge for tools
- **Parser**: `crates/executors/src/executors/opencode.rs`
- **Features**: Share bridge tool events

## Adding a New Executor

To normalize logs for a new executor:

1. **Create normalizer function** in `crates/executors/src/executors/<name>.rs`:

```rust
pub async fn normalize_logs(
    msg_store: &MsgStore,
    exit_signal: Option<ExitSignalSender>,
) -> Result<NormalizedConversation> {
    let mut entries = Vec::new();

    while let Some(msg) = msg_store.recv().await {
        match parse_message(&msg) {
            ParsedMessage::UserMessage(content) => {
                entries.push(NormalizedEntry {
                    timestamp: Some(Utc::now().to_rfc3339()),
                    entry_type: NormalizedEntryType::UserMessage,
                    content,
                    metadata: None,
                });
            }
            // Handle other message types...
        }
    }

    Ok(NormalizedConversation {
        entries,
        session_id: None,
        executor_type: "new_executor".to_string(),
        prompt: None,
        summary: None,
    })
}
```

2. **Handle stderr** using the shared processor:

```rust
use crate::logs::stderr_processor::process_stderr;

// In your normalizer
tokio::spawn(async move {
    process_stderr(stderr_rx, normalized_tx).await;
});
```

3. **Use automatic error classification**:

```rust
NormalizedEntryType::ErrorMessage {
    error_type: NormalizedEntryError::classify(&error_content),
}
```

4. **Track tool status** through the lifecycle:

```rust
// When tool is invoked
ToolStatus::Created

// When approved and running
ToolStatus::Success  // or Failed

// When denied
ToolStatus::denied_with_source(reason, DenialSource::User)

// When timed out
ToolStatus::timed_out_with_duration(requested_at)
```

## Normalization Flow

The complete data flow from raw agent output to UI display involves several stages:

```text
┌─────────────────────────────────────────────────────────────────────────┐
│                          DURING EXECUTION                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐    ┌────────────────┐    ┌─────────────────────────┐  │
│  │ Agent       │───▶│ MsgStore       │───▶│ LogBatcher              │  │
│  │ stdout/err  │    │ (in-memory)    │    │ (batches writes)        │  │
│  └─────────────┘    └───────┬────────┘    └────────────┬────────────┘  │
│                             │                          │               │
│                             │ push_msg()               │ flush()       │
│                             ▼                          ▼               │
│                    ┌────────────────┐    ┌─────────────────────────┐   │
│                    │ normalize_logs │    │ execution_process_logs  │   │
│                    │ (spawned task) │    │ (JSONL raw backup)      │   │
│                    └───────┬────────┘    └─────────────────────────┘   │
│                            │                                           │
│                            │ JsonPatch                                 │
│                            ▼                                           │
│                    ┌────────────────┐    ┌─────────────────────────┐   │
│                    │ log_entries    │───▶│ WebSocket               │   │
│                    │ (normalized)   │    │ (real-time UI)          │   │
│                    └────────────────┘    └─────────────────────────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│                          AFTER EXECUTION                                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. LogBatcher.finish() - Flush remaining buffered logs                 │
│  2. Await normalize_logs JoinHandle - Wait for normalization complete   │
│  3. MsgStore.push_finished() - Signal end of stream                     │
│  4. log_migration - Populate REST pagination from normalized entries    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Flow Stages

1. **Raw Capture**: Agent stdout/stderr streams into `MsgStore`
2. **Batched Write**: `LogBatcher` buffers messages, writes to `execution_process_logs` in JSONL format
3. **Real-time Normalization**: `normalize_logs()` task parses raw logs, emits `JsonPatch` entries
4. **Database Storage**: Normalized entries stored in `log_entries` table via JsonPatch operations
5. **WebSocket Streaming**: JsonPatch operations sent to frontend for real-time display

## Synchronization

Proper synchronization ensures all logs are captured before marking an execution as complete. This is critical for data integrity - without synchronization, logs may be lost or truncated.

### The Problem

```text
❌ Without synchronization:

┌─────────────┐     ┌──────────────┐     ┌────────────────┐
│ Agent exits │────▶│ push_finished│────▶│ Logs truncated │
│             │     │ immediately  │     │ (data loss!)   │
└─────────────┘     └──────────────┘     └────────────────┘
                           ▲
                           │ normalize_logs() still running!
                           │ LogBatcher still has buffered logs!
```

### The Solution

Two synchronization mechanisms ensure complete log capture:

#### 1. LogBatcher Finish Signal

The `LogBatcher` batches database writes for efficiency (100 messages or 250ms). Before completion:

```rust
// In spawn_exit_monitor/stop_execution:
log_batcher.finish(execution_id).await;  // Flush remaining logs
```

This flushes any buffered logs to `execution_process_logs` before the process is marked complete.

#### 2. JoinHandle Await Pattern

The `normalize_logs()` function returns a `JoinHandle<()>` that must be awaited:

```rust
// Trait definition
fn normalize_logs(
    &self,
    msg_store: Arc<MsgStore>,
    worktree_path: &Path
) -> JoinHandle<()>;

// Container stores the handle
container.store_normalization_handle(exec_id, norm_handle).await;

// Before completion, await with timeout
if let Some(norm_handle) = container.take_normalization_handle(&exec_id).await
    && tokio::time::timeout(Duration::from_secs(5), norm_handle)
        .await
        .is_err()
{
    tracing::warn!("Normalization timed out after 5 seconds");
}
```

### Complete Synchronization Flow

```text
✅ With synchronization:

┌─────────────┐     ┌──────────────┐     ┌─────────────────┐
│ Agent exits │────▶│ LogBatcher   │────▶│ Await normalize │
│             │     │ .finish()    │     │ JoinHandle (5s) │
└─────────────┘     └──────────────┘     └────────┬────────┘
                                                  │
                                                  ▼
                                         ┌─────────────────┐
                                         │ push_finished() │
                                         │ All logs safe!  │
                                         └─────────────────┘
```

### Key Implementation Points

| Component | File | Purpose |
|-----------|------|---------|
| `LogBatcherHandle::finish()` | `crates/services/src/services/log_batcher.rs` | Flush buffered logs for an execution |
| `store_normalization_handle()` | `crates/local-deployment/src/container.rs` | Store JoinHandle for later await |
| `take_normalization_handle()` | `crates/local-deployment/src/container.rs` | Retrieve and await the handle |
| 5-second timeout | Container exit handlers | Prevent hanging on slow normalization |

### Configuring the Timeout

The default 5-second timeout can be configured via environment variable:

```bash
# In .env or shell environment
VK_NORMALIZATION_TIMEOUT_SECS=10  # Increase for large log volumes
```

The timeout balances completeness with responsiveness:

- **Too short**: Risk losing final log entries still being processed
- **Too long**: UI appears frozen waiting for completion
- **Default (5 seconds)**: Sufficient for most normalization, logs warning if exceeded

If normalization times out, a warning is logged but execution continues. The raw logs in `execution_process_logs` remain available for manual recovery via the `migrate_logs` CLI.

## Monitoring

Normalization performance is tracked via metrics exposed through the diagnostics endpoints and periodic logging.

### Available Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `vk_normalization_total` | Counter | Total normalization operations |
| `vk_normalization_timeouts` | Counter | Number of timeouts (exceeded configured threshold) |
| `vk_normalization_timeout_rate` | Gauge | Timeout rate (0-1) |
| `vk_normalization_avg_duration_ms` | Gauge | Average normalization duration |
| `vk_normalization_latency_bucket{le="X"}` | Gauge | Latency distribution buckets |

### Accessing Metrics

**JSON API:**
```bash
curl http://localhost:3001/api/diagnostics
```

**Prometheus Format:**
```bash
curl http://localhost:3001/api/diagnostics/prometheus
```

### Periodic Logging

Normalization metrics are automatically logged every 5 minutes (if there's activity):

```text
INFO Normalization metrics total=42 timeouts=1 timeout_rate_pct="2.38" avg_duration_ms="127.45"
```

This helps identify:
- **High timeout rates**: May need to increase `VK_NORMALIZATION_TIMEOUT_SECS`
- **Slow average duration**: Potential performance issues with normalizers
- **Latency distribution**: Understanding typical completion times

## Recovery

When normalization times out or the server crashes during execution, raw logs are preserved and can be recovered.

### Automatic Recovery

On server startup, `recover_incomplete_executions()` automatically:
1. Scans for executions with `log_migration_state = 'pending'`
2. Loads raw logs from `execution_process_logs` (JSONL backup)
3. Normalizes and populates `log_entries` table
4. Updates migration state to `'completed'`

### Manual Recovery

For specific executions or troubleshooting:

```bash
# Run the migrate_logs CLI
cargo run --bin migrate_logs

# With verbose logging
RUST_LOG=debug cargo run --bin migrate_logs
```

The CLI:
- Loads `.env` for database configuration
- Processes all incomplete executions
- Reports count of recovered logs

## Frontend Integration

Normalized entries are sent to the frontend via WebSocket and displayed in `ProcessLogsViewer`:

- Virtual scrolling for large log volumes (react-virtuoso)
- ANSI color code support
- Expandable tool calls with diff viewing
- Approval buttons for pending approvals
- Error highlighting with classification badges

## Key Files

### Core Types

| File | Purpose |
|------|---------|
| `crates/executors/src/logs/mod.rs` | Core types: `NormalizedEntry`, `ToolStatus`, `NormalizedEntryError` |
| `crates/executors/src/logs/stderr_processor.rs` | Shared stderr processing logic |
| `crates/executors/src/logs/plain_text_processor.rs` | Plain text stream processing |
| `crates/executors/src/logs/utils/` | JsonPatch utilities, entry index tracking |

### Synchronization

| File | Purpose |
|------|---------|
| `crates/services/src/services/log_batcher.rs` | Batched database writes, `finish()` signal |
| `crates/local-deployment/src/container.rs` | JoinHandle storage, await on exit |
| `crates/services/src/services/log_migration.rs` | Post-execution log migration |

### Monitoring

| File | Purpose |
|------|---------|
| `crates/services/src/services/normalization_metrics.rs` | Metrics collection with latency buckets |
| `crates/server/src/routes/diagnostics.rs` | JSON and Prometheus endpoints |
| `crates/server/src/bin/migrate_logs.rs` | CLI for manual log recovery |

### Per-Executor Normalizers

| File | Purpose |
|------|---------|
| `crates/executors/src/executors/claude/` | Claude Code JSON-RPC parsing |
| `crates/executors/src/executors/codex/normalize_logs.rs` | Codex event parsing |
| `crates/executors/src/executors/acp/normalize_logs.rs` | ACP (Gemini, Qwen) parsing |
| `crates/executors/src/executors/cursor.rs` | Cursor JSONL parsing |
| `crates/executors/src/executors/copilot.rs` | Copilot text + log file parsing |
| `crates/executors/src/executors/droid/normalize_logs.rs` | Droid structured parsing |

### Frontend

| File | Purpose |
|------|---------|
| `frontend/src/components/process/ProcessLogsViewer.tsx` | Virtual scrolling log viewer |
| `frontend/src/components/process/NormalizedEntryView.tsx` | Entry type rendering |

## Related Documentation

- [Executor Logging](/features/executor-logging) - User guide for log viewing
- [Log Migration](/architecture/log-migration) - Post-execution log processing
- [Execution Sync](/architecture/execution-sync) - Real-time synchronization
